[{"categories":["python","conda"],"content":"介绍 Conda 可以用来在一台机器上管理不同的 Python 版本。\n比如项目 A 使用 python3.10，项目 B 使用 python3.12。\nConda 有两个版本：Anaconda 和 Miniconda。\n一般选择 Miniconda 就可以了，Anaconda 只是多了一些科学计算相关的包。\n安装 这里只讲 Miniconda 安装。\n1 2 3 4 5 6 7 8 # 创建一个文件夹，用来存放 miniconda 和它将要管理的 Python 相关文件。 # 文件夹名字可以随便写，只要后面命令保持一致即可 mkdir -p ~/miniconda3 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh # 执行安装 bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3 rm ~/miniconda3/miniconda.sh 惊！这个安装用的 shell 脚本竟然有 142M（里面包含一些可执行文件内容）。 根据你使用的 shell 类型进行初始化。init 之后，重启下终端，就自动激活 conda 环境了。\n1 2 3 4 5 6 7 ~/miniconda3/bin/conda init bash 或 ~/miniconda3/bin/conda init zsh 或 ~/miniconda3/bin/conda init fish 或 ~/miniconda3/bin/conda init \u003c其他\u003e 默认情况下，每次进入终端，都会打开一个名为base的 conda 环境，一点用都没有。\n所以重启终端后，执行下面的命令禁用它：\n1 conda config --set auto_activate_base false 使用 帮助信息 conda -h：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 $ conda -h usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ... conda is a tool for managing and deploying applications, environments and packages. options: -h, --help Show this help message and exit. -v, --verbose Can be used multiple times. Once for detailed output, twice for INFO logging, thrice for DEBUG logging, four times for TRACE logging. --no-plugins Disable all plugins that are not built into conda. -V, --version Show the conda version number and exit. commands: The following built-in and plugins subcommands are available. COMMAND activate Activate a conda environment. clean Remove unused packages and caches. compare Compare packages between conda environments. config Modify configuration values in .condarc. content-trust Signing and verification tools for Conda create Create a new conda environment from a list of specified packages. deactivate Deactivate the current active conda environment. doctor Display a health report for your environment. export Export a given environment info Display information about current conda install. init Initialize conda for shell interaction. install Install a list of packages into a specified conda environment. list List installed packages in a conda environment. notices Retrieve latest channel notifications. package Create low-level conda packages. (EXPERIMENTAL) remove (uninstall) Remove a list of packages from a specified conda environment. rename Rename an existing environment. repoquery Advanced search for repodata. run Run an executable in a conda environment. search Search for packages and display associated information using the MatchSpec format. update (upgrade) Update conda packages to the latest compatible version. 创建指定 python 版本的 conda 环境：\n1 2 3 4 conda create --name \u003cenv_name\u003e python=\u003cversion\u003e # 创建一个名称为 myenv 的 python3.10 版本的环境 conda create --name myenv python=3.10 查看已有 conda 环境：\n1 conda env list 切换 conda 环境：\n1 conda activate \u003cenv_name\u003e 删除某个 conda 环境：\n1 conda remove --name \u003cenv_name\u003e --all 退出 conda 环境：\n1 conda deactivate 其他 conda \u0026 venv conda 管理的是 python 多版本，venv 管理的是多项目的依赖。\n这俩并不冲突，可以理解成 conda 管理的比 venv 高一层。\n你可以在某一个 conda 环境里在使用 venv 创建项目的虚拟环境。\n并且在创建完虚拟环境后，也可以在 conda 环境之外进入该虚拟环境。\n在该虚拟环境里安装的包，只在该虚拟环境内有效。\n多语言支持 实际上，conda 不仅可以用来管理 python，还可以管理「其他语言」。比如创建一个 go1.21 的 conda 环境：\n1 conda create --name go1.21 go=1.21 据我目前理解，conda 要解决的问题有以下两点：\n1、在同一台机器上创建与切换某个编程语言的多个版本环境。\n2、将语言依赖包集中在 conda 自己的 channel 去下载，并提供一些优化支持。比如可以用 conda install numpy=1.21 替代 pip install numpy==1.21\n个人觉得第一点是比较好的，确实某些时候有这个需要。\n至于第二点，嗯。。。反正我没这个需求。\n商用风险 官方说明里有这么一段话： 翻译过来就是：\nMiniconda 可供任何人免费使用！但是，只有个人和小型组织（少于 200 名员工）才能免费访问 Anaconda 的公共软件包存储库。大型组织和任何嵌入或镜像 Anaconda 存储库的人都需要付费许可证。有关详细信息，请参阅 TOS。\nMiniforge 还有一个和 conda 类似的社区驱动的项目 miniforge:\nhttps://github.com/conda-forge/miniforge.\nhttps://conda-forge.org/docs/user/introduction/\n据了解是为了解决 conda 在包管理方面的问题（主要是慢、分散），以及对 arm 平台的支持，用法和 conda 一样。如果只用来管理语言多版本环境，这俩没啥区别。\n卸载 https://docs.anaconda.com/anaconda/install/uninstall/\n1 2 3 4 5 conda activate conda init --reverse --all # 注意这里是你 conda 的安装目录，默认是 miniconda3 rm -rf ~/miniconda3 ","description":"","tags":["python","conda"],"title":"Conda 安装和使用","uri":"/posts/conda/"},{"categories":["sharkd"],"content":"介绍 官方接口文档：https://wiki.wireshark.org/sharkd-JSON-RPC\nsharkd 是 wireshark 里用来解析数据包的模块，可以单独编译和使用。\nsharkd 可执行文件未包含在标准 Wireshark 二进制包（Windows MSI 等）中，因此必须从源代码构建。\nsharkd 提供了接口用于数据查询（使用 tcp 或本地 socket）。\n发送给 sharkd 进程的请求格式为 {\"jsonrpc\":\"2.0\",\"id\":1, \"method\": \"xxx\"}。 其中的 id 为非 0 的数字，表示请求序号，请求和应答根据 id 进行关联，所以请尽量保证每个请求 id 不重复。\n编译：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 git clone --depth=1 https://github.com/wireshark/wireshark cd wireshark # debian 系使用这个，其他平台在tools目录下找对应的文件即可 tools/debian-setup.sh mkdir build cd build cmake -DBUILD_wireshark=OFF .. make -j # 编译出来的文件在 ./run/sharkd 使用 启动 sharkd 守护进程：\n1 2 3 4 $ sharkd -a unix:/tmp/sharkd.sock Running as user \"root\" and group \"root\". This could be dangerous. Sharkd listening on: unix:/tmp/sharkd.sock 使用代码和 sharkd 交互：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import socket def get_json_bytes(json_string): return bytes((json_string + '\\n'), 'utf-8') def json_send_recv(s, json) -\u003e str: s.sendall(get_json_bytes(json)) data = s.recv(1024) return data[:].decode('utf-8') s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) s.connect(\"/tmp/sharkd.sock\") json_string = '{\"jsonrpc\":\"2.0\",\"id\":1, \"method\": \"status\"}' print('send: ' + json_string) rx_json = json_send_recv(s, json_string) print('recv: ' + rx_json) s.close() 让 sharkd 加载抓包文件，向 sharkd 接口发送以下内容：\n1 {\"jsonrpc\":\"2.0\",\"id\":1, \"method\": \"load\", \"file\": \"/tmp/test.pcap\"} 对 sharkd 来说，文件是一次性加载的，如果加载后文件发生变化，sharkd 并不会动态更新，所以需要开发人员给 sharkd 发送上述指令重新加载。\n更多使用方法请参考官方文档。\n其他 还有一个经常被搜到的文档，https://wiki.wireshark.org/Development/sharkd\n应该是过时了，就不要看了，里面内容不对，很迷惑人。\n","description":"","tags":["sharkd"],"title":"wireshark 之 sharkd 使用","uri":"/posts/sharkd/"},{"categories":["ai"],"content":"概念 首先明确一点，AI 输出内容存在随机性。\nAI 推理是指人工智能在处理问题时，根据已有的数据和模型，进行逻辑推断和生成答案的过程。这个过程包括了从大量的数据中抽取有用信息、应用已学的规则或模式、并最终得出一个可能的回答。由于 AI 生成的结果有时会有所不同，主要有以下几个原因：\n随机性：许多 AI 模型在生成回答时会引入一定的随机性。例如，在生成文本时，模型可能会从多个合适的选项中随机选择一个，因此同一个问题的回答可能会有所不同。\n上下文理解：AI 的回答会受到上下文的影响。不同的上下文或问法可能导致模型关注不同的细节，从而产生不同的回答。\n训练数据：AI 的回答基于其训练数据和学习到的模式。如果训练数据有多种可能的解释或观点，模型的回答可能会体现这些多样性。\n模型参数：不同的模型版本或配置可能会产生不同的回答。参数调整或模型更新也可能影响生成的内容。\n生成策略：在生成答案时，AI 模型可能会使用不同的策略，例如长度限制、内容多样性等，这也会导致回答的变化。\n如果有外部知识库的辅助，AI 输出的内容就会有更好的确定性\n检索增强生成（RAG - Retrieval-Augmented Generation）是指对大型语言模型输出进行优化，使其能够在生成响应之前引用训练数据来源之外的权威知识库。大型语言模型（LLM）用海量数据进行训练，使用数十亿个参数为回答问题、翻译语言和完成句子等任务生成原始输出。在 LLM 本就强大的功能基础上，RAG 将其扩展为能访问特定领域或组织的内部知识库，所有这些都无需重新训练模型。这是一种经济高效地改进 LLM 输出的方法，让它在各种情境下都能保持相关性、准确性和实用性。\nAI Agent（一般称 AI 代理 或 AI 智能体）\nAI 聊天机器人主要靠“说”来回答你的问题，而 AI Agent 则会**“动”起来完成具体的任务**，就像人类助理一样，在你忙不过来的时候替你完成一些工作，区别就是用 AI 来驱动而不是人脑驱动。\n从原理上说，AI Agent 的核心驱动力是大模型，在此基础上增加规划（Planning）、记忆（Memory）和工具使用（Tool Use）三个关键组件。\nAI Agent = LLM（大模型） + Planning（规划） + Memory（记忆） + Tools（工具）\nLLM（大模型）：就像园丁的智慧和知识库，它阅读了海量的园艺书籍和资料，不仅知道各种植物的名字，还懂得如何照顾它们。在 AI Agent 中，LLM 提供了庞大的信息存储和处理能力，以理解和响应我们提出的各种问题。\nPlanning（规划）：园丁需要规划整个花园的布局。AI Agent 的规划功能，就像园丁制定种植计划，决定先种哪些花草、后种哪些蔬菜，或者如何分步骤修剪树冠。\nMemory（记忆）：这类似于园丁的笔记本，记录了每个植物的种植时间、生长情况和前一次施肥的时间。记忆模块让 AI Agent 能记住以往的经验和已经完成的任务，确保不会重复错误。\nTools（工具）：就是园丁的用具，比如铲子、水壶和剪刀。AI Agent 的工具模块，指的是它可以运用的各种软件和程序，帮助它执行复杂的任务，就像园丁用工具进行园艺活动一样。\nWorkflow更像是一组预定的规则和步骤的组合，通过这些步骤的顺序执行，来实现一个复杂的任务。Workflow 的每一步可能涉及多个 Agent 来完成特定的子任务。\nAgent 和 Workflow 是相辅相成的关系。在一个复杂的 Workflow 中，可能需要多个 Agent来完成不同的任务。例如，在一个自动化的客户服务系统中，可能有一个 Agent 负责与用户互动、另一个 Agent 负责后台数据处理，还有一个 Agent 负责决策制定。Workflow 则负责协调这些 Agent，使得整个任务可以流畅地执行。因此，Workflow 可以被看作是 Agent 操作的框架，它规定了每个 Agent 的角色、任务顺序以及如何在不同任务之间传递信息。\nRAG、Agent、Workflow 有什么区别和联系\nRAG（Retrieval-Augmented Generation）是近年来流行的一种结合信息检索和生成的 AI 模型，它通过先检索相关信息再进行文本生成来提供更准确的答案。与 Agent 和 Workflow 不同，RAG 专注于单一任务的优化，即通过增强生成模型的输入质量来提高输出的准确性。Agent 和 Workflow 则更关注于任务的执行过程和多任务协作。简而言之，RAG 是在单个任务（如问答生成）中提高表现的技术，而 Agent 和 Workflow 则是在多任务场景下实现任务的高效执行与协作的框架。\n应用 AI 产品案例严选\nChatDev 是一家虚拟软件公司，通过各种不同角色的智能体运营，包括执行官，产品官，技术官，程序员 ，审查员，测试员，设计师 等。这些智能体形成了一个多智能体组织结构，其使命是“通过编程改变数字世界”。ChatDev 内的智能体通过参加专业的功能研讨会来 协作，包括设计、编码、测试和文档编写等任务。\nCoze 是新一代一站式 AI Bot 开发平台。无论你是否有编程基础，都可以在 Coze 平台上快速搭建基于 AI 模型的各类问答 Bot，从解决简单的问答到处理复杂逻辑的对话。并且，你可以将搭建的 Bot 发布到各类社交平台和通讯软件上，与这些平台/软件上的用户互动。\nDify 是一款开源的大语言模型 (LLM) 应用开发平台。它融合了后端即服务（Backend as Service）和 LLMOps 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。即使你是非技术人员，也能参与到 AI 应用的定义和数据运营过程中。\n参考资料 大模型幻觉\nAI Agent 来了，但它是什么？ AI 代理介绍、趋势全解读\n什么时候该用多智能体是不是一定要用多智能体？\n为什么大佬都在说 Agent 是未来？换个角度来谈一谈\n吴恩达红杉美国 AI 峰会谈 Agent Workflow 以及 4 种主流设计模式_腾讯新闻\n","description":"","tags":["ai"],"title":"AI Agent 和 workflow 介绍","uri":"/posts/ai-agent-workflow/"},{"categories":["ai","comfyUI","flux"],"content":"下载 comfyUI 1 2 3 4 5 6 7 8 9 git clone https://github.com/comfyanonymous/ComfyUI.git # 启动 python 虚拟环境 cd ComfyUI/ python3 -m vevn venv \u0026 source ./venv/bin/activate # 安装依赖 pip install -r requirements.txt 安装 comfyUI-Manager 1 2 3 4 cd ComfyUI/custom_nodes/ git clone https://github.com/ltdrdata/ComfyUI-Manager.git cd ComfyUI/custom_nodes/ComfyUI-Manager pip install -r requirements.txt 下载模型 1 2 3 4 5 cd ComfyUI/models/checkpoints wget https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev-fp8.safetensors cd ComfyUI/models/vae wget https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/ae.sft 启动 1 python main.py --cpu --listen 0.0.0.0 浏览器访问 http://localhost:8188\n输入配置，点击 Queue Prompt 开始执行，等待 30 分钟后终于得到一张图（谁能送我一个 H100，我想试试 😊 。。。\n同样的提示词，steps 设置成 20，跑了第二遍：\nso，自由就是张开翅膀，拥抱阳光？\n","description":"","tags":["ai","comfyUI","flux"],"title":"CPU 模式下 comfyUI 运行 flux","uri":"/posts/comfyui-flux-demo/"},{"categories":["Mac","windows"],"content":"使用 Mac 的”启动转换助理“安装 windows 双系统时，走到最后一步了，出现如下错误：\nWindows 无法更新计算机的启动配置，安装无法继续。\n搜索了一圈，有说需要重置 SMC 的，有说打电话问 Apple 客服的，这两个方案都试了，无效。\n一开始的镜像是从 https://msdn.itellyou.cn/ 上随便找了个 win10 下载的，猜测是选的镜像版本太老，有些驱动不支持导致的，所以直接去微软官方下载了最新的 win10 版本，问题解决。 微软官方 win10 下载地址：https://www.microsoft.com/zh-cn/software-download/windows10ISO\n","description":"","tags":["mac","windows"],"title":"Mac 安装 Windows 双系统","uri":"/posts/mac-win10/"},{"categories":["ai"],"content":"部署 ollama ollama 是一个运行大模型的框架，这里选择使用 docker 的方式启动 ollama:\n1 docker run -d -v ./ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama 启动成功后，选择想要的模型，这里以阿里通义千问最小的模型 (352M) 为例：\n1 docker exec -it ollama ollama run qwen2:0.5b 运行起来后，可以在命令行进行交互，输入/bye 或 ctrl + c 退出。\n更多模型可在这里找： https://ollama.com/library\n部署 Open WebUI 有很多开源的 UI 库允许你从浏览器访问模型，这里以 Open WebUI 为例，更多工具请参考：https://github.com/ollama/ollama/tree/main?tab=readme-ov-file#web--desktop\n1 2 # OLLAMA_BASE_URL替换成你机器的IP地址，例如： OLLAMA_BASE_URL=http://192.168.1.110:11434 docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v ./open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main 然后浏览器访问 3000 端口即可，用户名密码随便注册一个即可。\n默认是无限制注册的，可以登录后在设置里禁用掉。\n点击右上角头像 --- 管理员面板 --- 设置\n其他 测试环境为一台无显卡的 oracle 服务器 ( 4 核 24G )。 跑大小为 8G 的模型 (llama3.1)，平均每秒输出 4 个字符，勉强能用，再大的就跑不了了。\n如果选择不使用 docker 部署 ollama, 想修改 ollama 的模型存储路径以及监听地址的话，需要修改文件 /etc/systemd/system/ollama.service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [Unit] Description=Ollama Service After=network-online.target [Service] # 修改模型存储路径， 默认为 /usr/share/ollama/.ollama Environment=\"OLLAMA_MODELS=/data/ollama\" # ollama监听地址，默认为 127.0.0.1 Environment=\"OLLAMA_HOST=0.0.0.0\" ExecStart=/usr/bin/ollama serve User=ollama Group=ollama Restart=always RestartSec=3 [Install] WantedBy=default.target 修改完以后记得执行：\n1 2 systemctl daemon-reload systemctl enable ollama 参考资料：\nhttps://hub.docker.com/r/ollama/ollama\nhttps://github.com/ollama/ollama\n","description":"","tags":["ai"],"title":"本地部署大模型","uri":"/posts/ollama-llama/"},{"categories":["linux"],"content":"暂停当前的前台进程 1 ctrl + z 查看当前被暂停的作业列表 1 jobs 输出的每一个作业都有一个序号，可以被 bg 和 fg 使用。\n将暂停的进程放到后台继续运行（bg） 1 bg 默认是将最近一个被暂停的进程恢复运行并放到后台。\n可以加作业序号，指定操作哪个作业。\n例如将序号为 2 的作业放到后台继续执行：\n1 bg %2 将暂停的进程放到前台继续运行（fg） 使用方式和 bg 同理。\n1 fg 默认是将最近一个被暂停的进程恢复运行并放到前台。\n可以加作业序号，指定操作哪个作业。\n例如将序号为 2 的作业放到前台继续执行：\n1 fg %2 disown 的使用 默认情况下，当前会话终端后，所有的作业都会被释放。\n可以使用 disown 命令将一个进程从当前的 shell 会话中分离出来，使其不再受该会话的控制。首先将进程放到后台，然后执行：\n1 disown %1 %1 是作业号，可以用 jobs 命令查看并确认作业号。\n直接在启动时将命令放在后台运行（nohup） 1 nohup some_cmd \u0026 ","description":"","tags":["linux"],"title":"Linux 作业控制","uri":"/posts/linux-jobs/"},{"categories":["git"],"content":" 仅限在可控状态下使用，否则会被别人打死。\n批量修改 git 仓库提交人信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/sh git filter-branch --env-filter ' an=\"$GIT_AUTHOR_NAME\" am=\"$GIT_AUTHOR_EMAIL\" cn=\"$GIT_COMMITTER_NAME\" cm=\"$GIT_COMMITTER_EMAIL\" if [ \"$GIT_COMMITTER_EMAIL\" = \"\u003cold_user\u003e@gmail.com\" ] then cn=\"\u003cnew_user\u003e\" cm=\"\u003cnew_user\u003e@gmail.com\" fi if [ \"$GIT_AUTHOR_EMAIL\" = \"\u003cold_user\u003e@outlook.com\" ] then an=\"\u003cnew_user\u003e\" am=\"\u003cnew_user\u003e@gmail.com\" fi export GIT_AUTHOR_NAME=\"$an\" export GIT_AUTHOR_EMAIL=\"$am\" export GIT_COMMITTER_NAME=\"$cn\" export GIT_COMMITTER_EMAIL=\"$cm\" ' 修改完以后 git push --force。\n","description":"","tags":["git"],"title":"批量修改 git 仓库提交人信息","uri":"/posts/git-filter-branch/"},{"categories":["mac","tools"],"content":"Mac 上使用虚拟机安装了 Windows，若想正常使用cmd + c、cmd + v等快捷键，按以下步骤操作。\n安装 AutoHotkey，这里选择下载 v1 版本，因为下面的脚本只支持 v1。\n从 GitHub 上下载一个脚本https://github.com/stroebjo/autohotkey-windows-mac-keyboard。\n把里面的MacKeyboard.ahk这个文件下载下来。\n用编辑器打开MacKeyboard.ahk文件，可以看到里面实际上是做了一些映射。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 ;----------------------------------------- ; Mac keyboard to Windows Key Mappings ;========================================= ; -------------------------------------------------------------- ; NOTES ; -------------------------------------------------------------- ; ! = ALT ; ^ = CTRL ; + = SHIFT ; # = WIN ; ; Debug action snippet: MsgBox You pressed Control-A while Notepad is active. #InstallKeybdHook #SingleInstance force SetTitleMatchMode 2 SendMode Input ; -------------------------------------------------------------- ; Mac-like screenshots in Windows (requires Windows 10 Snip \u0026 Sketch) ; -------------------------------------------------------------- ; Capture entire screen with CMD/WIN + SHIFT + 3 #+3::send #{PrintScreen} ; Capture portion of the screen with CMD/WIN + SHIFT + 4 #+4::#+s ; -------------------------------------------------------------- ; media/function keys all mapped to the right option key ; -------------------------------------------------------------- RAlt \u0026 F7::SendInput {Media_Prev} RAlt \u0026 F8::SendInput {Media_Play_Pause} RAlt \u0026 F9::SendInput {Media_Next} F10::SendInput {Volume_Mute} F11::SendInput {Volume_Down} F12::SendInput {Volume_Up} ; swap left command/windows key with left alt ;LWin::LAlt ;LAlt::LWin ; add a semicolon in front of this line if you want to disable the windows key ; Remap Windows + Left OR Right to enable previous or next web page ; Use only if swapping left command/windows key with left alt ;Lwin \u0026 Left::Send, !{Left} ;Lwin \u0026 Right::Send, !{Right} ; Eject Key ;F20::SendInput {Insert} ; F20 doesn't show up on AHK anymore, see #3 ; F13-15, standard windows mapping F13::SendInput {PrintScreen} F14::SendInput {ScrollLock} F15::SendInput {Pause} ;F16-19 custom app launchers, see http://www.autohotkey.com/docs/Tutorial.htm for usage info F16::Run http://twitter.com F17::Run http://tumblr.com F18::Run http://www.reddit.com F19::Run https://facebook.com ; -------------------------------------------------------------- ; OS X system shortcuts ; -------------------------------------------------------------- ; Make Ctrl + S work with cmd (windows) key #s::Send, ^s ; Selecting #a::Send, ^a ; Copying #c::Send, ^c ; Pasting #v::Send, ^v ; Cutting #x::Send, ^x ; Opening #o::Send ^o ; Finding #f::Send ^f ; Undo #z::Send ^z ; Redo #y::Send ^y ; New tab #t::Send ^t ; close tab #w::Send ^w ; Close windows (cmd + q to Alt + F4) #q::Send !{F4} ; Remap Windows + Tab to Alt + Tab. Lwin \u0026 Tab::AltTab ; minimize windows #m::WinMinimize,a ; -------------------------------------------------------------- ; OS X keyboard mappings for special chars ; -------------------------------------------------------------- ; Map Alt + L to @ !l::SendInput {@} ; Map Alt + N to \\ +!7::SendInput {\\} ; Map Alt + N to © !g::SendInput {©} ; Map Alt + o to ø !o::SendInput {ø} ; Map Alt + 5 to [ !5::SendInput {[} ; Map Alt + 6 to ] !6::SendInput {]} ; Map Alt + E to € !e::SendInput {€} ; Map Alt + - to – !-::SendInput {–} ; Map Alt + 8 to { !8::SendInput {{} ; Map Alt + 9 to } !9::SendInput {}} ; Map Alt + - to ± !+::SendInput {±} ; Map Alt + R to ® !r::SendInput {®} ; Map Alt + N to | !7::SendInput {|} ; Map Alt + W to ∑ !w::SendInput {∑} ; Map Alt + N to ~ !n::SendInput {~} ; Map Alt + 3 to # !3::SendInput {#} ; -------------------------------------------------------------- ; Custom mappings for special chars ; -------------------------------------------------------------- ;#ö::SendInput {[} ;#ä::SendInput {]} ;^ö::SendInput {{} ;^ä::SendInput {}} ; -------------------------------------------------------------- ; Application specific ; -------------------------------------------------------------- ; Google Chrome #IfWinActive, ahk_class Chrome_WidgetWin_1 ; Show Web Developer Tools with cmd + alt + i #!i::Send {F12} ; Show source code with cmd + alt + u #!u::Send ^u #IfWinActive ; 开头的表示注释。\n+ 表示 SHIFT 键\n# 表示 win 键\n! 表示 ALT 键\n^ 表示 CTRL 键\n所以 #1::Send ^1 表示将 win + 1 或者 cmd + 1 快捷键映射成 ctrl + 1。\n这里我增加了以下内容，用于多标签页窗口（chrome、文件浏览器等）中使用 cmd + 数字切换标签。\n1 2 3 4 5 6 7 8 9 10 ; select tab #1::Send ^1 #2::Send ^2 #3::Send ^3 #4::Send ^4 #5::Send ^5 #6::Send ^6 #7::Send ^7 #8::Send ^8 #9::Send ^9 这里有一个比较奇怪的问题，如果上面的第一行 ; select tab 换成了中文注释 ; 选择标签页，上述配置就会失效，除非第一行和第二行中间加一个空行，原因不明，保险起见用英文写注释内容吧。\n然后，windows 里快捷键 win + r，输入 shell:startup，回车后会打开开机启动文件夹。\n将上面的MacKeyboard.ahk文件拖到打开的文件夹里，重启电脑即可。\n","description":"","tags":["mac","tools"],"title":"虚拟机中使用 Mac 快捷键","uri":"/posts/mac-windows-autohotkey/"},{"categories":["mac","python"],"content":"如果直接执行pip install mysqlclient，会报错，需要先安装依赖：\n1 2 3 4 brew install mysql-client # 必须加这个环境变量，否则后面pip安装还是会报错，可以将这个加到 ~/.bash_profile 或者 ～/.zshrc 中 export PKG_CONFIG_PATH=\"$(brew --prefix)/opt/mysql-client/lib/pkgconfig\" 然后再执行：\n1 pip install mysqlclient ","description":"","tags":["mac","python"],"title":"Mac 下为 Python 安装 mysqlclinet","uri":"/posts/mac-python-mysqlclinet/"},{"categories":["linux"],"content":"Linux 命令行快捷键：\n1 2 3 4 5 6 7 8 9 ctrl + u 清除当前行 ctrl + w 删除当前光标的单词 ctrl + f/b 前进后退 ctrl + p 上一条命令 ctrl + a/e 到行首/行尾 Iterm2 快捷键：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 command + 左右方向键 切换标签 command + option + 方向键 切换屏幕 command + [ 或 command + ] 切换屏幕 command + ; 查看历史命令 command + shift + h 查看剪贴板历史 command + opt + b 回看操作历史，左右键调整时间条 command + shift + i 多窗口同时输入模式，再次按可以取消该模式 # 当打开很多窗口时，可以使用这个进行搜索（窗口名、窗口中的命令、用户名等）；也可以进行会话配置等操作。 command + shift + o 快速打开 回看历史默认存储大小设置： 如果不小心关闭了窗口，可以使用cmd + z恢复，超时时间设置位置： ","description":"","tags":["linux","mac","iterm2"],"title":"Linux \u0026 iterm2 常用快捷键","uri":"/posts/linux-shortkeys/"},{"categories":["mac"],"content":"背景 出于信任问题，手机上切换成 iPhone 自带输入法好多年了，无奈因为使用习惯问题 Mac 上一直用的搜狗输入法（实际上只是自带输入法无法实现 shift 切换中英文的小问题）。今天终于研究了下，完美解决。\nMac 原生的中英文切换是 Caps Lock 键。\n但 Caps Lock 除了使用不习惯外，更重要的是，即使习惯了也不能解决下面这个情况：\n我期望在按完 shift 后，能把 golang 这个字符出现在搜索框里，一般的输入法都是这个逻辑，但 Mac 不行。 解决方案 使用知名改键神器：Karabiner-Elements\n找到下图位置，添加自定义规则： 输入以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 { \"description\": \"Use left_shift to switch input sources\", \"manipulators\": [ { \"conditions\": [ { \"bundle_identifiers\": [ \"^com\\\\.teamviewer\\\\.TeamViewer$\", \"^com\\\\.vmware\\\\.horizon$\", \"^com\\\\.vmware\\\\.fusion$\", \"^com\\\\.vmware\\\\.view$\", \"^com\\\\.parallels\\\\.desktop$\", \"^com\\\\.parallels\\\\.vm$\", \"^com\\\\.parallels\\\\.desktop\\\\.console$\", \"^org\\\\.virtualbox\\\\.app\\\\.VirtualBoxVM$\", \"^com\\\\.citrix\\\\.XenAppViewer$\", \"^com\\\\.vmware\\\\.proxyApp\\\\.\", \"^com\\\\.parallels\\\\.winapp\\\\.\" ], \"type\": \"frontmost_application_unless\" } ], \"from\": { \"key_code\": \"left_shift\", \"modifiers\": { \"optional\": [ \"caps_lock\" ] } }, \"parameters\": { \"basic.to_if_alone_timeout_milliseconds\": 200, \"basic.to_if_held_down_threshold_milliseconds\": 200 }, \"to\": [ { \"key_code\": \"left_shift\", \"lazy\": true } ], \"to_if_alone\": [ { \"key_code\": \"spacebar\", \"modifiers\": \"control\" } ], \"to_if_held_down\": [ { \"key_code\": \"left_shift\" } ], \"type\": \"basic\" } ] } 然后在下图设置处，使其对自带键盘生效： 嗯。。。舒服了～\n参考资料 https://idawnlight.com/2022/use-left-shift-to-switch-input-sources-on-macos/\n","description":"","tags":["mac","输入法","改键","karabiner"],"title":"Mac 原生输入法配置","uri":"/posts/mac-input-shift/"},{"categories":["vscode"],"content":"我的终端使用的是 zsh，在 vscode 里打开时显示有乱码。\n解决办法是在 settings.json 中加入：\n1 \"terminal.integrated.fontFamily\": \"MesloLGS NF\", ","description":"","tags":["vscode"],"title":"解决 vscode 终端乱码","uri":"/posts/vscode-terminal-settings/"},{"categories":["python"],"content":"前言 作为一门优秀的脚本语言，Python 在语法层面提供了很多好玩又实用的语法，俗称语法糖，正确的使用这些技巧能让代码看起来更优雅，更 Pythonic，这里列举几个。\n简化 if ... else 1 2 3 4 5 6 7 8 9 10 11 #!/usr/bin/env python3 def main(): animals = ['cat','dog','bird','pig'] if \"dog\" in animals: print(\"dog 在列表里\") else: print(\"dog 不在列表里\") if __name__ == '__main__': main() 以上代码明显代码行数比较多，可以简化为如下写法\n1 2 3 4 5 6 7 8 #!/usr/bin/env python3 def main(): animals = ['cat','dog','bird','pig'] print(\"dog 在列表里\") if \"dog\" in animals else print(\"dog 不在列表里\") if __name__ == '__main__': main() for ... else 先看一段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/usr/bin/env python3 def main(): flag = False animals = ['cat','dog','bird','pig'] for o in animals: if o == \"dog\": flag = True break if flag == True: print(\"dog 在列表里\") if __name__ == '__main__': main() 代码很简单，需要使用 for 循环执行一段逻辑，如果命中某个条件，则使用一个变量 flag 做下标记，并且终止 for 循环，循环结束之后，判断 flag 是否等于 True 来执行另一段逻辑。这种场景，借助了一个额外的变量，比较啰嗦，在 Python 里有个更优雅的写法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/usr/bin/env python3 def main(): animals = ['cat','dog','bird','pig'] for o in animals: if o == \"dog\": break else: print(\"dog 不在列表里\") if __name__ == '__main__': main() 这段代码的意思就是，for 循环执行过程中，如果遇到了 break 语句，则退出 for 循环之后，就不再执行 else 部分的代码。\nwith 语句 打开文件，遍历文件，然后再关闭文件句柄，我们一般会这么写\n1 2 3 4 5 6 7 8 9 10 11 12 #!/usr/bin/env python3 def main(): f = open(\"a.txt\") try: for line in f: print(line) finally: f.close() if __name__ '__main__': main() 上述写法需要自己去调用 close 方法，保证句柄被正常释放。 使用 python 中的 with 方法，就不用显示的去调用 close 了，并且即使中间出现异常，也可以。\n1 2 3 4 5 6 7 8 9 #!/usr/bin/env python3 def main(): with open(\"a.txt\") as f: for line in f: print(line) if __name__ '__main__': main() 实际上 with 方法并不是帮你调用了 close 方法，而是调用了 with 返回对象的__exit__()方法。\ncontextlib.closing() 如果一个类实现了 close() 方法，就可以借助 with 和 contextlib.closing() 帮你自动调用 close 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/usr/bin/env python3 import contextlib class Request(object): def __init__(self): pass def do(self): print(\"do something\") def close(self): print(\"close\") def main(): with contextlib.closing(Request()) as r: r.do() if __name__ == '__main__': main() ","description":"","tags":["python"],"title":"Python 语法糖","uri":"/posts/python-tips/"},{"categories":["mac"],"content":"前言 连接远程服务器的工具有很多，使用人数最多的两款非 xshell 和 SecureCRT 莫属，但是这两款一个不支持 Mac，一个收费，破解版又不敢装。\n比较简单的替代方案是使用iterm2。\n目前网上介绍最多的是以下两种方式实现的自动登录：\nshell脚本 + expect + iterm2触发器 shell脚本 + sshpass 这两种方式都显得很蹩脚，还得用 shell 脚本。 而且密码还明文暴露在 shell 脚本里。 对密码和 shell 不敏感的小伙伴自己去搜下怎么实现的吧，此处不推荐。\n这里介绍的方式是纯使用iterm2实现，可以做到不暴露明文密码，配置非常简单，像使用 xshell 一样丝滑。\n演示 cmd + o 打开服务器列表，方向键选择要登录的机器，回车，提示输入密码； option + cmd + f打开密码管理器，方向键选择密码，回车，即可登录；（这一步通过配置触发器其实可以省略，后面有介绍） 此时若重复步骤 1，借助 ssh 会话复制已不需要输入密码。 配置 添加服务器 点击iterm2-Preferences-Profiles，按图示配置一个新的 profile。\n配置密码管理器 点击 iterm2-Window-Password Manager，按图示配置一个密码，配置完后可按ESC键关闭该窗口。 配置触发器 找到对应Profiles里面的Advanced选项，找到Triggers，点击Edit\n配置成如下图所示，这样当执行cmd + o时，就只需要选择机器，回车后，就能自动弹出密码了，不再需要option + cmd + f这个操作：\n第一列表示当终端出现哪些字符的时候触发这个配置\n第二列是触发动作，这里选择打开密码管理器\n第三列是定位到密码管理器里面的哪个密码配置\n后面两列不知道什么意思。。。都选上了\n配置 SSH 会话复制、会话保持 使用过 SecureCRT 和 Xshell 的同学都知道有个 session copy 的功能，其实 ssh 本身就支持这个，只需在~/.ssh/config文件里添加几行配置即可。\n1 2 3 4 5 6 7 8 # 会话复制相关配置 Host * ControlMaster auto ControlPath ~/.ssh/%r@%h:%p.socket ControlPersist yes ServerAliveInterval 10 # 每隔10s发一次心跳 ServerAliveCountMax 3 # 三次心跳没响应则关闭连接 其他 ","description":"","tags":["iterm2","mac","ssh"],"title":"Mac 下使用 iterm2 配置 ssh","uri":"/posts/mac-iterm2-ssh/"},{"categories":["blog"],"content":"前言 介绍如何创建一个自动构建的静态网站，并且将博客源文件 (markdown、主题配置等) 与 public 静态目标文件分开存放。\nHugo hugo 有两个版本，标准版和扩展版，建议直接使用扩展版，以便更好的兼容大多数主题。\n1 CGO_ENABLED=1 go install -tags extended github.com/gohugoio/hugo@latest 基本使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 初始化一个hugo项目 $ hugo new site myblog \u0026\u0026 cd myblog # 下载主题 $ git init \u0026\u0026 git submodule add --depth 1 https://github.com/reuixiy/hugo-theme-meme.git themes/meme # ... 参照 https://github.com/reuixiy/hugo-theme-meme 进行配置 # 生成静态网站文件(public文件夹) $ hugo 或者 # 启动一个本地的web服务，可用浏览器访问 http://localhost:1313 查看效果 $ hugo server Github 为了能使用 github pages，需要创建一个公开仓库，用来存放编译好的静态文件，仓库名必须为\u003cusername\u003e.github.io ，username是你的github账户名，后面会通过github actions自动将私有仓库生成的网站内容推送到该仓库，但在自动化之前，需要先有一个对该仓库有读写权限的 token。\n访问 https://github.com/settings/personal-access-tokens/new 将创建后得到的 token 保存备用，具体配置见下图：\n再创建一个仓库来存放博客源文件，仓库名随意，本文中用myblog代替，推荐配置成私有仓库。\n进入刚创建的myblog，依次选择settings - Secrets and variables - Actions，点击New repository secret，将刚才创建的 token 配置给变量PERSONAL_TOKEN。\n在myblog里新建文件.github/workflows/hugo.yml\n示例中的配置只需要改两行（33、37 行）\n33 行需要改成你自己的仓库\n如果你有自己的域名的话，在配置好域名的 cname 后，可以配置第 37 行，否则删掉第 37 行。\nhugo.yml内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 name: deploy on: push: workflow_dispatch: # schedule: # Runs everyday at 8:00 AM # - cron: \"0 0 * * *\" jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \"latest\" extended: true - name: Build Web run: hugo - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: \u003cusername\u003e/\u003cusername\u003e.github.io PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} cname: www.YOUR_DOMAIN.com 在myblog里新建文件.gitignore内容如下：\n1 2 public/* resources/* 在myblog里配置好 hugo，git push后就可以自动触发上面的 workflow，等到 \u003cusername\u003e.github.io中出现 hugo 生成的静态文件，等待一会，就可以通过\u003cusername\u003e.github.io或者你自己的域名访问你的网站了。\n更多 关于怎么配置 cname，参考 这里。\n","description":"","tags":["blog","github","hugo"],"title":"使用 hugo+github 部署静态博客","uri":"/posts/hugo-github-pages/"},{"categories":["severless"],"content":"参考资料：\n什么是 serverless：hhttps://jimmysong.io/kubernetes-handbook/usecases/understanding-serverless.html\nserverless 具体是怎么运行的：hhttps://www.cnblogs.com/serverlesscloud/p/13141645.html\nserverless 开发指南：hhttps://cn.serverless.com/blog/sls-dev-suggest-1\n关键字： 无状态 、函数计算 、 极致微服务、冷启动 、热启动\n","description":"","tags":["severless"],"title":"serverless 基础","uri":"/posts/serverless%E5%9F%BA%E7%A1%80/"},{"categories":["linux"],"content":"如果服务器端 ssh 看起来一切正常，22 端口也正常，但是客户端 ssh 连接不上，通常报错类似下面这样：\n1 2 $ ssh fast@10.1.8.16 Connection closed by 10.1.8.16 port 22 这种情况可通过重置服务端 ssh 证书解决，命令如下：\n1 2 3 4 5 6 7 # Delete old ssh host keys $ rm /etc/ssh/ssh*host*\\* # Reconfigure OpenSSH Server $ dpkg-reconfigure openssh-server # Update all ssh client(s) ~/.ssh/known_hosts files 参考资料：hhttps://serverfault.com/questions/471327/how-to-change-a-ssh-host-key\n","description":"","tags":["linux"],"title":"reset-ssh-key","uri":"/posts/reset-ssh-key/"},{"categories":["vim"],"content":"光标放在数字上：\nctrl + a 数字加 1 ctrl + x 数字减 1 将某一列数字递增的加 1： 选中该列，按g，再按ctrl + a\n1 2 3 4 5 1 1 1 1 1 将变成\n1 2 3 4 5 2 3 4 5 6 ","description":"","tags":["vim"],"title":"vim 中数字增加或减少","uri":"/posts/vim%E4%B8%AD%E6%95%B0%E5%AD%97%E5%A2%9E%E5%8A%A0%E6%88%96%E5%87%8F%E5%B0%91/"},{"categories":["k8s"],"content":"将 helm chart 推送到指定的仓库下，默认会推送到\"library\"下的“helm chart“\n1 2 3 4 5 6 7 8 9 $ helm repo add --ca-file ca.crt --username=admin myrepo https://\u003charbor-domain\u003e/chartrepo/artifacts $ helm repo list NAME URL myrepo https://harbor.local.com/chartrepo/artifacts $ helm plugin install https://github.com/chartmuseum/helm-push $ helm cm-push --ca-file ca.crt airflow-8.8.0.tgz myrepo 效果： ","description":"","tags":["k8s"],"title":"将 helm chart 推送到 harbor","uri":"/posts/helm-chart-to-harbor/"},{"categories":["k8s"],"content":"环境初始化 参考文档 k3s 离线部署：https://docs.k3s.io/zh/installation/airgap\nkube-vip：https://kube-vip.io/docs/usage/k3s/\n部署环境 1 2 3 4 5 6 7 8 9 10 11 # 需要使用hostnamectl set-hostname xxx对所有机器修改主机名 # 3台server 172.16.99.11 server01 172.16.99.12 server02 172.16.99.13 server03 # 3台agent 172.16.99.14 agent01 172.16.99.15 agent02 172.16.99.16 agent03 准备一个和 server 同网段且空闲的虚拟 IP 给 kube-vip，本文档以 172.16.99.100 为例。\nkube-vip 是为了能用一个固定的虚拟 IP 充当负载均衡器来访问集群，提高集群的可用性\n这个虚拟 IP 在初始化 server 和 agent 的时候都要用，会添加到三台 server 的 lo 接口\n最终安装完后的效果 开始安装 安装初始化 一、准备离线文件\n从https://github.com/k3s-io/k3s/releases下载 k3s 镜像包和 k3s 二进制文件。\n版本无所谓，选最新的就行，推荐选择 .tar.zst 的 (压缩率高)。\n二、初始化所有的 agent 和 server\n将下载的 k3s 二进制文件放到/usr/local/bin，并且加可执行权限 chmod +x /usr/local/bin/k3s\n创建目录/var/lib/rancher/k3s/agent/images/，并将下载的镜像文件放进去（不需要解压）\n将安装脚本下载下来，命令 curl -sfL https://get.k3s.io -o install.sh\n三、准备 kube-vip 镜像\n在本地下载 kube-vip 镜像，并传输到所有的 server 机器上。\n1 2 3 4 5 6 7 $ docker pull ghcr.io/kube-vip/kube-vip:v0.5.0 $ docker save ghcr.io/kube-vip/kube-vip:v0.5.0 -o kube-vip.tar $ scp kube-vip.tar root@172.16.99.11:~ $ scp kube-vip.tar root@172.16.99.12:~ $ scp kube-vip.tar root@172.16.99.13:~ 初始化 server01 注意修改对应的 IP 地址\n1 INSTALL_K3S_SKIP_DOWNLOAD=true ./install.sh server --cluster-init --tls-san=172.16.99.100 在 server01 上执行以下命令获取 token，后续安装需要用到。\n1 cat /var/lib/rancher/k3s/server/token 接下来由于后面的 server 和 agent 都需要用到虚拟 IP 来进行注册，所以需要先安装 kube-vip。\n安装 kube-vip 参考文档：https://kube-vip.io/docs/usage/k3s/\n首先，导入 kube-vip 镜像。由于 k3s 默认使用的不是 docker，是 containerd，所以导入镜像的方式和 docker 有点区别，使用 ctr 命令。\n-n k8s.io // k3s 和 k8s 指定了要使用 k8s.io 这个命名空间\n--digests=true // 将导入的镜像中的 tag 信息一起导入进去\n1 $ ctr -n k8s.io images import kube-vip.tar --digests=true 创建两个文件：\nkube-vip-rbac.yaml\n参考：https://kube-vip.io/docs/usage/k3s/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 apiVersion: v1 kind: ServiceAccount metadata: name: kube-vip namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \"true\" name: system:kube-vip-role rules: - apiGroups: [\"\"] resources: [\"services/status\"] verbs: [\"update\"] - apiGroups: [\"\"] resources: [\"services\", \"endpoints\"] verbs: [\"list\",\"get\",\"watch\", \"update\"] - apiGroups: [\"\"] resources: [\"nodes\"] verbs: [\"list\",\"get\",\"watch\", \"update\", \"patch\"] - apiGroups: [\"coordination.k8s.io\"] resources: [\"leases\"] verbs: [\"list\", \"get\", \"watch\", \"update\", \"create\"] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: system:kube-vip-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:kube-vip-role subjects: - kind: ServiceAccount name: kube-vip namespace: kube-system kube-vip.yaml\n参考：https://kube-vip.io/docs/installation/daemonset/#generating-a-manifest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 apiVersion: apps/v1 kind: DaemonSet metadata: labels: app.kubernetes.io/name: kube-vip-ds app.kubernetes.io/version: v0.5.0 name: kube-vip-ds namespace: kube-system spec: selector: matchLabels: app.kubernetes.io/name: kube-vip-ds template: metadata: labels: app.kubernetes.io/name: kube-vip-ds app.kubernetes.io/version: v0.5.0 spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node-role.kubernetes.io/master operator: Exists - matchExpressions: - key: node-role.kubernetes.io/control-plane operator: Exists containers: - args: - manager env: - name: vip_arp value: \"false\" - name: port value: \"6443\" - name: vip_interface value: lo - name: vip_cidr value: \"32\" - name: cp_enable value: \"true\" - name: cp_namespace value: kube-system - name: vip_ddns value: \"false\" - name: svc_enable value: \"true\" - name: bgp_enable value: \"true\" - name: bgp_routerinterface value: \"ens18\" - name: bgp_routerid valueFrom: fieldRef: fieldPath: status.podIP - name: bgp_as value: \"65000\" - name: bgp_peeraddress - name: bgp_peerpass - name: bgp_peeras value: \"65000\" - name: bgp_peers value: 172.16.99.11:65000::false,172.16.99.12:65000::false,172.16.99.13:65000::false - name: address value: 172.16.99.100 - name: prometheus_server value: :2112 image: ghcr.io/kube-vip/kube-vip:v0.5.0 imagePullPolicy: IfNotPresent name: kube-vip resources: {} securityContext: capabilities: add: - NET_ADMIN - NET_RAW hostNetwork: true serviceAccountName: kube-vip tolerations: - effect: NoSchedule operator: Exists - effect: NoExecute operator: Exists updateStrategy: {} 其中只需要修改这一部分： 将其中 bgp_peers 的 value 中的 IP 地址换成三台 server 的地址。 address的value 是前面提到的当前网络中一个未使用的虚拟 IP 地址。\n1 2 3 4 - name: bgp_peers value: 172.16.99.11:65000::false,172.16.99.12:65000::false,172.16.99.13:65000::false - name: address value: 172.16.99.100 修改后，执行部署：\n1 2 kubectl apply -f kube-vip-rbac.yaml kubectl apply -f kube-vip.yaml 至此，后面的机器初始化就非常简单了。\n初始化 server02 和 server03 注意修改对应的 IP 地址和 token\n1 INSTALL_K3S_SKIP_DOWNLOAD=true ./install.sh server --cluster-init --tls-san=172.16.99.100 --server https://172.16.99.100:6443 --token {server01 上获取的token} 导入 kube-vip 镜像\n1 $ ctr -n k8s.io images import kube-vip.tar --digests=true 初始化 agent 注意修改对应的 IP 地址和 token\n1 INSTALL_K3S_SKIP_DOWNLOAD=true ./install.sh agent --server https://172.16.99.100:6443 --token {server01 上获取的token} ","description":"","tags":["k8s","k3s","kube-vip"],"title":"离线部署 k3s 集群","uri":"/posts/%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2k3s%E9%9B%86%E7%BE%A4/"},{"categories":["linux"],"content":"awk awk 指定多个分隔符 awk -F '[;:]'（使用;或:进行分割）\n1 2 获取最后一列 awk '{print $NF}' find find . -type f -name \"*.png\" -exec ls -l {} \\;\n{} 是一个替换符，表示前面找到的内容 \\; 是exec的默认结尾标识符\nfind /sys/devices/virtual/net -name iflink -exec grep -H -w 11 {} \\;\ngrep 增加-H选项后，可以显示文件名\n如果目录下有软连接的外部文件夹，默认 find 不会显示软连接里的内容，如果需要可以加上-L，但是注意，如果软连接有循环，则会不停的输出，慎用，比如： xargs # xargs -t # 在执行前先打印处要执行的命令 # xargs -I {} # 设置一个符号{}表示管道前面的某一行输出内容，以便后续复杂命令进行替换 # xargs -P `nproc` # 并发数，默认为1，如果置0表示让xargs使用尽可能多的并发数，这里`nproc`是cpu核数 docker ps -q | xargs -t -I {} docker exec {} sh -c \"find /sys -name iflink | xargs grep -w 14\" 等价于 # 最后的 grep -H 表示查找到内容后显示对应的文件名 docker ps -q | xargs -t -I {} docker exec {} sh -c \"find /sys -name iflink | xargs -I {} grep -w 14 {} -H\" grep 或运算：\n-E 参数加上|\nlsof -i | grep -E 'epc-ims:|IPv6'\n与运算：\n实际上就是正则.+表示任意 N 个字符\nlsof -i | grep -E \"8323.+38911\"\nlsof lsof = list open file\n1 2 3 4 5 -i # 查看网络 -c # 某进程打开的文件 -p # 某进程号打开的文件 -r # 重复执行时间间隔，单位秒 -n # 将出现的主机名转换成IP显示 lsof -i tcp\nlsof -i udp\nlsof -n -i tcp\nlsof -c 进程名\nlsof -p pid\nlsof -r 1 每秒执行一次\ncurl 自动重定向：\n1 curl qq.com -L 只显示请求头：\n1 curl qq.com -I 添加请求头：\n1 2 # 请求头的名字最好都按规范首字母大写 curl 192.168.190.1 -H \"Host: a.b.c\" -H \"User-Agent: Chrome\" ","description":"","tags":["linux","命令"],"title":"Linux 命令备忘录","uri":"/posts/linux-cmd/"},{"categories":["linux"],"content":"\nhttps://tinychen.com/20200414-iptables-principle-introduction/\nhttps://blog.csdn.net/qq_29344757/article/details/81128150\n","description":"","tags":["linux","网络"],"title":"iptables","uri":"/posts/iptables/"},{"categories":["linux"],"content":"主要依赖两个文件，这两个文件在宿主机和容器内都有\n1 2 3 4 5 # 某虚拟设备对在`当前`机器 / 容器的ID编号 /sys/devices/virtual/net/***/ifindex # 某虚拟设备对在`对方`机器 / 容器的ID编号 /sys/devices/virtual/net/***/iflink 以虚拟设备vethdedb37c为例： ip link show vethdedb37c显示内容14: vethdedb37c@if13:...，14表示当前机器的设备 ID，@if13中的13是对端的 ID。\ndocker ps -q | xargs -t -I {} docker exec {} sh -c \"find /sys -name iflink | xargs grep -w 14\"\n查找所有容器，看谁的iflink值为14\n定位到虚拟设备另一端在容器0a469babdbc9。\n也可以用ethtool -S vethdedb37c看到对端的 ID 是13 命令解释：xargs\n","description":"","tags":["linux","网络"],"title":"查找虚拟设备对对端位置","uri":"/posts/%E6%9F%A5%E6%89%BE%E8%99%9A%E6%8B%9F%E8%AE%BE%E5%A4%87%E5%AF%B9%E5%AF%B9%E7%AB%AF%E4%BD%8D%E7%BD%AE/"},{"categories":["linux"],"content":"\n文件类型 -- 属主 -- 属组 -- 其他用户\n可读（4） 可写（2） 可执行（1）\n755 表示只有属主有读写执行权限，其他人只能读 (4) 和执行 (1)\n除了数字另一种表示方法： 可读（r） 可写（w） 可执行（x）\n用户：user（u） 组：group（g） 其他人：other（o）\nchmod a-x file 表示把所有人对该文件的执行权限收回\n","description":"","tags":["linux"],"title":"文件权限","uri":"/posts/%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90/"},{"categories":["docker"],"content":" docker 命令里已经集成了 compose，所以尽量使用 docker compose 而不是 docker-compose\n出于数据安全考虑，docker compose 和 docker一样，默认不会删除存储卷，如果想删除，可以使用以下命令 删除镜像和存储卷\n1 2 3 4 5 # 删除存储卷 $ docker compose down -v # 删除存储卷以及镜像 $ docker compose down --rmi all -v 注意：\n使用docker compose up -d启动后，如果docker-compose.yaml所在的目录名或路径发生变化，docker compose down时会失败。 如果想让docker compose down执行的快一些，可以使用-t参数来控制等待的秒数。 ","description":"","tags":["docker"],"title":"docker compose","uri":"/posts/docker-compose/"},{"categories":["linux"],"content":"使用ip a或者ifconfig区分不出来网卡和网桥。\n使用ls -l /sys/class/net可以判断 包含virtual的应该都是虚拟网桥。 包含pci的都是物理网卡。\n如何区分网桥和虚拟设备对 brctl show：\n第一列是网桥 最后一列是虚拟设备对 更多关于虚拟设备对参考：查找虚拟设备对对端位置\n","description":"","tags":["linux","网络"],"title":"查看机器上的网卡","uri":"/posts/%E6%9F%A5%E7%9C%8B%E6%9C%BA%E5%99%A8%E4%B8%8A%E7%9A%84%E7%BD%91%E5%8D%A1/"},{"categories":["docker"],"content":"前言 使用下面的命令可以释放 docker 产生的无用的空间。\n清理未使用的构建缓存 docker builder prune -a\n1 2 3 4 5 6 7 8 9 10 11 $ docker help builder prune Usage: docker builder prune Remove build cache Options: -a, --all Remove all unused build cache, not just dangling ones --filter filter Provide filter values (e.g. \"until=24h\") -f, --force Do not prompt for confirmation --keep-storage bytes Amount of disk space to keep for cache 清理未使用的镜像 docker image prune -a\n1 2 3 4 5 6 7 8 9 10 $ docker help image prune Usage: docker image prune [OPTIONS] Remove unused images Options: -a, --all Remove all unused images, not just dangling ones --filter filter Provide filter values (e.g. \"until=\u003ctimestamp\u003e\") -f, --force Do not prompt for confirmation 清理未使用的挂载 docker volume prune -a\n1 2 3 4 5 6 7 8 9 10 $ docker help volume prune Usage: docker volume prune [OPTIONS] Remove unused local volumes Options: -a, --all Remove all unused volumes, not just anonymous ones --filter filter Provide filter values (e.g. \"label=\u003clabel\u003e\") -f, --force Do not prompt for confirmation 其他 docker network prune - 清理未使用的网络（注意：包含 stop 状态容器相关的网络，慎用）\n","description":"","tags":["docker"],"title":"释放 docker 占用空间","uri":"/posts/%E9%87%8A%E6%94%BEdocker%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4/"},{"categories":["docker"],"content":"操作镜像 一些时候，我们可能只是对表格的结构不满意，希望自己组织列；或者不希望有标题，这样方便其它程序解析结果等，这就用到了 Go 的模板语法。\n下面的命令会直接列出镜像结果，并且只包含镜像 ID 和仓库名：\n1 2 3 4 5 6 7 $ docker image ls --format \"{{.ID}}: {{.Repository}}\" 5f515359c7f8: redis 05a60462f8ba: nginx fe9198c04d62: mongo 00285df0df87: \u003cnone\u003e 329ed837d508: ubuntu 329ed837d508: ubuntu 1 2 3 4 5 6 7 8 $ docker image ls --format \"table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\" IMAGE ID REPOSITORY TAG 5f515359c7f8 redis latest 05a60462f8ba nginx latest fe9198c04d62 mongo 3.2 00285df0df87 \u003cnone\u003e \u003cnone\u003e 329ed837d508 ubuntu 18.04 329ed837d508 ubuntu bionic 我们希望看到在 mongo:3.2 之后建立的镜像，可以用下面的命令：\n1 2 3 4 $ docker image ls -f since=mongo:3.2 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB nginx latest 05a60462f8ba 5 days ago 181 MB 想查看某个位置之前的镜像也可以，只需要把 since 换成 before 即可。\n此外，如果镜像构建时，定义了 LABEL，还可以通过 LABEL 来过滤。\n1 2 $ docker image ls -f label=com.example.version=0.1 ... 删除镜像和容器 删除所有未使用的镜像docker image prune -a 删除所有已停止的容器 docker container prune 删除数据卷 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。\n无主的数据卷可能会占据很多空间，要清理请使用以下命令：\n1 $ docker volume prune 参考资料 https://yeasy.gitbook.io/docker_practice/\n","description":"","tags":["docker"],"title":"docker 使用","uri":"/posts/docker%E4%BD%BF%E7%94%A8/"},{"categories":["docker"],"content":"ADD 和 COPY 区别 如果 \u003c源路径\u003e 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 \u003c目标路径\u003e 去。\n在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 ubuntu 中：\nFROM scratch ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz / ... 但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 ADD 命令了。\n在 Docker 官方的Dockerfile 最佳实践文档中要求，尽可能的使用 COPY 😄，因为 COPY 的语义很明确，就是复制文件而已，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。\n另外需要注意的是，ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。\nCMD 和 ENTRYPOINT 区别 仅在使用docker run时有区别，容器运行起来后使用docker exec时没有区别。\nCMD 想增加参数-i的话，还需要把完整命令再写一遍\n1 2 3 4 5 FROM ubuntu:18.04 RUN apt-get update \\ \u0026\u0026 apt-get install -y curl \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* CMD [ \"curl\", \"-s\", \"http://myip.ipip.net\" ] 1 $ docker run myip curl -s http://myip.ipip.net -i ENTRYPOINT 可以直接在docker run 后面增加参数，docker 会进行追加操作\n1 2 3 4 5 FROM ubuntu:18.04 RUN apt-get update \\ \u0026\u0026 apt-get install -y curl \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* ENTRYPOINT [ \"curl\", \"-s\", \"http://myip.ipip.net\" ] docker run myip -i 等价于 curl -s http://myip.ipip.net -i\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $ docker run myip 当前 IP：61.148.226.66 来自：北京市 联通 $ docker run myip -i HTTP/1.1 200 OK Server: nginx/1.8.0 Date: Tue, 22 Nov 2016 05:12:40 GMT Content-Type: text/html; charset=UTF-8 Vary: Accept-Encoding X-Powered-By: PHP/5.6.24-1~dotdeb+7.1 X-Cache: MISS from cache-2 X-Cache-Lookup: MISS from cache-2:80 X-Cache: MISS from proxy-2_6 Transfer-Encoding: chunked Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006 Connection: keep-alive 当前 IP：61.148.226.66 来自：北京市 联通 ARG 和 ENV 区别 ARG 格式：ARG \u003c参数名\u003e[=\u003c默认值\u003e]\n构建参数和 ENV 的效果一样，都是设置环境变量。所不同的是，ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。\nDockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 --build-arg \u003c参数名\u003e=\u003c值\u003e 来覆盖。\n灵活的使用 ARG 指令，能够在不修改 Dockerfile 的情况下，构建出不同的镜像。\nARG 指令有生效范围，如果在 FROM 指令之前指定，那么只能用于 FROM 指令中。\n1 2 3 4 5 ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine RUN set -x ; echo ${DOCKER_USERNAME} 使用上述 Dockerfile 会发现无法输出 ${DOCKER_USERNAME} 变量的值，要想正常输出，你必须在 FROM 之后再次指定 ARG\n1 2 3 4 5 6 7 8 9 # 只在 FROM 中生效 ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine # 要想在 FROM 之后使用，必须再次指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine # 在FROM 之后使用变量，必须在每个阶段分别指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} FROM ${DOCKER_USERNAME}/alpine # 在FROM 之后使用变量，必须在每个阶段分别指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} ENV 格式有两种：\nENV \u003ckey\u003e \u003cvalue\u003e ENV \u003ckey1\u003e=\u003cvalue1\u003e \u003ckey2\u003e=\u003cvalue2\u003e... ENV设置的环境变量在镜像构建和容器运行过程中都有效。\n","description":"","tags":["docker"],"title":"dockerfile 使用","uri":"/posts/dockerfile%E4%BD%BF%E7%94%A8/"},{"categories":["docker"],"content":"安装 docker\n1 2 $ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun 建立 docker 组：\n1 $ sudo groupadd docker 将当前用户加入 docker 组：\n1 $ sudo usermod -aG docker $USER ","description":"","tags":["docker"],"title":"docker 安装","uri":"/posts/docker%E5%AE%89%E8%A3%85/"},{"categories":["linux"],"content":"根目录下可用磁盘大小为 22G，实际物理磁盘有 46.58G，vgs 可看到还有 21.76（50%）的空间没被使用。\n扩展逻辑卷，并将VFree的空间全部分配逻辑卷/dev/mapper/ubuntu--vg-ubuntu--lv\n这个命令将逻辑卷扩展到卷组中的所有可用空间。如果你只想分配部分可用空间，可以使用 -L 选项并指定具体的大小，例如 -L +10G 表示增加 10GB。 ext4 文件系统使用resize2fs xfs 文件系统使用 xfs_growfs\n1 2 3 $ lvextend -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv $ resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv ","description":"","tags":["linux"],"title":"Linux 修改磁盘大小","uri":"/posts/linux-disk-change/"},{"categories":["其他"],"content":"简介 oracle 免费服务器不支持在界面上更换操作系统，这里借助第三方工具boot.netboot.xyz重装。\n对于不能 ssh 登录的机器参考这个：https://ooly.cc/archives/linux/361/\n忘记密码参考：https://iweec.com/731.html\n下载 netboot amd：\n1 2 cd /boot/efi/EFI wget https://boot.netboot.xyz/ipxe/netboot.xyz.efi arm\n1 2 cd /boot/efi/EFI wget https://boot.netboot.xyz/ipxe/netboot.xyz-arm64.efi 启动 cloud shell 连接 在实例详情里选择 控制台连接 -- 启动Cloud Shell连接 等待显示For more information about troubleshooting ...即可。 重新引导实例 选择重新引导 -- 强制重新引导实例\n在下方的 Cloud Shell 里按几下ESC，进入BIOS后选择 Boot Maintenance Manager -- Boot From File -- \u003cEFI\u003e，再找到对应的 netboot 文件，回车。 选择Linux Network Installs，后续安装操作系统即可。 忘记密码 在 bios 设置之后，直接启动，然后在启动虚拟机出现启动菜单的时候就按“e”键进入编辑选项，选择第一项！\n按方向下键一直到倒数第二行，修改两处，首先将 ro 改为 rw，即只读改为可读写权限，然后在尾部加入 init=/bin/sh 这个文件修改时候小心一点！\n然后按 Ctrl+x。\n执行 passwd 命令，修改 root 密码，密码要输入两次要求两次密码要一致。\n执行命令 exec /sbin/init 来正常启动，或者用命令 exec /sbin/reboot 重启就 OK 了。\n","description":"","tags":["其他"],"title":"Oracle 服务器使用 netboot 重装系统","uri":"/posts/oracle-server-netboot/"},{"categories":["linux"],"content":" 1 2 3 4 5 6 7 8 没有数据发送后，多长时间发送保活探测包 /proc/sys/net/ipv4/tcp_keepalive_time 保活探测包多久发一次 /proc/sys/net/ipv4/tcp_keepalive_intvl 最多发几次保活探测包 /proc/sys/net/ipv4/tcp_keepalive_probes https://juejin.cn/post/7142654287493988359\n","description":"","tags":["linux","网络"],"title":"tcp 保活","uri":"/posts/tcp%E4%BF%9D%E6%B4%BB/"},{"categories":["linux"],"content":"参考 https://www.runoob.com/linux/linux-user-manage.html https://www.cnblogs.com/carriezhangyan/p/10552496.html\nuseradd 是一个 linux 命令，但是它提供了很多参数在用户使用的时候根据自己的需要进行设置；\nadduser 是一个 perl 脚本，在使用的时候会出现类似人机交互的界面，提供选项让用户填写和选择，这个命令比起 useradd 来说比较简单，也比较傻瓜。\nadduser 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # adduser git Adding user `git' ... Adding new group `git' (1004) ... Adding new user `git' (1004) with group `git' ... Creating home directory `/home/git' ... Copying files from `/etc/skel' ... Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully Changing the user information for git Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] y# ls /homegit # grep git /etc/passwdgit:x:1004:1004:,,,:/home/git:/bin/bash useradd（不建议使用） 1 2 3 4 5 6 7 8 9 10 11 12 13 useradd有大量的参数供我们进行个性化设置。useradd的参数如下： -c 备注 加上备注。并会将此备注文字加在/etc/passwd中的第5项字段中 -d 用户主文件夹。指定用户登录所进入的目录，并赋予用户对该目录的的完全控制权 -e 有效期限。指定帐号的有效期限。格式为YYYY-MM-DD，将存储在/etc/shadow -f 缓冲天数。限定密码过期后多少天，将该用户帐号停用 -g 主要组。设置用户所属的主要组 -G 次要组。设置用户所属的次要组，可设置多组 -M 强制不创建用户主文件夹 -m 强制建立用户主文件夹，并将/etc/skel/当中的文件复制到用户的根目录下 -p 密码。输入该帐号的密码 -s shell。用户登录所使用的shell -u uid。指定帐号的标志符user id，简称uid useradd这个命令创建的是普通账号，并不能用来登录系统。 ","description":"","tags":["linux"],"title":"用户和用户组","uri":"/posts/%E7%94%A8%E6%88%B7%E5%92%8C%E7%94%A8%E6%88%B7%E7%BB%84/"},{"categories":["linux"],"content":"rsync(remote sync)，即远程同步，不过也可用于本地文件同步，通常在增量更新的场景下比 scp 更快更方便。\nrsync 常用参数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -a 包含了-rtplgoD -r 同步目录时要加上，类似cp时的-r选项 -v 同步时显示一些信息，让我们知道同步的过程 -l 保留软连接 -L 加上该选项后，同步软连接的源文件（若另外一台机器里没有源文件，则同步软件连接过去也是无效的） -p 保持文件的权限属性 -o 保持稳健的属主 -g 保持稳健的属组 -D 保持设备文件信息 -t 保持文件的时间属性 -P 显示同步过程，比如速率，比-v更详细 -u 如果目标中的文件比源文件还有新，则不同步，以目标文件中新的为主 -z 传输时压缩（加快传输速度，节省带宽） --delete 删除目标目录中源目录里没有的文件 --exclude 过滤指定文件，如--exclude \"logs\"会把文件名包含Logs的文件或者目录过滤掉不同步 最常用的几种方式：\n普通同步：\n1 $ rsync -avr mylocaldir root@192.168.1.100:/path/to/dst/ 同步并删除远端多余的文件：\n1 $ rsync -avr --delete mylocaldir root@192.168.1.100:/path/to/dst/ 如果远端文件日期比较新，则不覆盖：\n1 $ rsync -avr -u mylocaldir root@192.168.1.100:/path/to/dst/ 忽略某些本地文件：\n1 $ rsync -avr -u mylocaldir --exclude aaa* --exclude bbb* root@192.168.1.100:/path/to/dst/ ","description":"","tags":["linux"],"title":"rsync 文件同步","uri":"/posts/rsync%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5/"},{"categories":["其他"],"content":"Mac:\n1 2 3 4 5 6 7 8 // 将输出复制至剪贴板 $ echo \"hello\" | pbcopy // 将文件中的内容全部复制至剪贴板 $ pbcopy \u003c remade.md // 将剪切板中的内容粘贴至文件 $ pbpaste \u003e remade.md Linux:\n1 2 # 需要带界面的才能用，apt install xclip $ echo \"hello\" | xclip ","description":"","tags":["其他"],"title":"命令行内容输出到剪贴板","uri":"/posts/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%86%85%E5%AE%B9%E8%BE%93%E5%87%BA%E5%88%B0%E5%89%AA%E8%B4%B4%E6%9D%BF/"},{"categories":["其他"],"content":"发送伪造 syn 握手包：\n1 2 3 4 5 6 7 -c 次数 -p 目标端口 -a 源IP -s 源端口 -S 攻击类型是Syn flood hping3 192.168.190.1 -c 1 -p 6106 -S -a 172.22.0.27 -s 31399 hping3 192.168.190.1 -c 1 -p 6109 -S -a 172.22.0.29 -s 31683\n","description":"","tags":["其他"],"title":"hping3 使用","uri":"/posts/hping3%E4%BD%BF%E7%94%A8/"},{"categories":["linux"],"content":" 1 2 3 4 5 6 7 # enp22s0f3 是网卡名 # 添加 ip addr add 192.168.0.1/16 dev enp22s0f3 #删除 ip addr del 192.168.0.1/16 dev enp22s0f3 ","description":"","tags":["linux","网络"],"title":"临时修改网卡地址","uri":"/posts/%E4%B8%B4%E6%97%B6%E4%BF%AE%E6%94%B9%E7%BD%91%E5%8D%A1%E5%9C%B0%E5%9D%80/"},{"categories":["golang"],"content":"文章 https://www.bennhuang.com/posts/wire/\nhttps://www.51cto.com/article/720059.html\n感受 大型项目，依赖很多的时候才会有用。\n","description":"","tags":["golang"],"title":"Go 依赖注入","uri":"/posts/go%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"},{"categories":["golang"],"content":"UTC UTC（Coordinated Universal Time），即协调世界时，对应的是格林尼治标准时间。 国内位于东八区，和 UTC 相差 8 小时，所以时间转换时需要考虑时区问题。\n字符串格式的时间 (比如 \"2023-09-01 11:22:33\")，转换成 golang 的 time.Time时默认得到的是 UTC 时间。\n标准库 默认的 time.Parse在标准库中的实现如下： 如果要指定时区，需要用到函数 time.LoadLocation，它在标准库中的实现如下： 其中入参 name 的取值可以用命令 timedatectl list-timezones来查看： 除了上述可选的入参外，还有一个特殊参数“Local”，表示让程序根据所在机器的默认时区进行转换。传入“Local”可以使代码更加标准，兼容性更强，但是有些老六不改系统时区，就比较坑了。所以要么你直接写死“Asia/Shanghai”，要么记得使用“timedatectl set-timezone Asia/Shanghai”修改系统时区（注意这里为什么不是 Asia/Beijing？我也不知道。。。它就是没有这个参数）。\n测试 以下测试代码，可以看出来加上时区后的效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package main import ( \"fmt\" \"time\" ) func main() { // 待转换的日期字符串 timeStr := \"2023-09-01 11:22:33\" fmt.Println(\"======parseTime:\") { t, err := parseTime(timeStr) if err != nil { panic(err) } fmt.Println(t.Location()) fmt.Println(t.String()) fmt.Println(t.Unix()) } fmt.Println(\"======parseTimeWithLocation:\") { t, err := parseTimeWithLocation(timeStr) if err != nil { panic(err) } fmt.Println(t.Location()) fmt.Println(t.String()) fmt.Println(t.Unix()) } } // 带时区的转换 func parseTimeWithLocation(timeStr string) (time.Time, error) { // l, err := time.LoadLocation(\"Asia/Shanghai\") l, err := time.LoadLocation(\"Local\") if err != nil { return time.Time{}, err } return time.ParseInLocation(\"2006-01-02 15:04:05\", timeStr, l) } // 默认时间转换 func parseTime(timeStr string) (time.Time, error) { return time.Parse(\"2006-01-02 15:04:05\", timeStr) } 如果不知道自己的时区，可以使用命令 timedatectl status看下对应的时区： ","description":"","tags":["golang"],"title":"Go 时区问题","uri":"/posts/go-timezone/"},{"categories":["其他"],"content":"只启动 wireshark\nMac 下启动多个 wireshark 实例时使用，但可能不稳定\n1 2 3 4 5 /Applications/Wireshark.app/Contents/MacOS/Wireshark 或者 open -n /Applications/Wireshark.app 启动 wireshark 并且直接开始抓包：\n目标机器需要安装 apt install dumpcap\n1 cd /Applications/Wireshark.app/Contents/MacOS \u0026\u0026 ssh root@10.1.8.1 'dumpcap -w - -f \"not port 22\"' -i vmbr1 | ./Wireshark -k -i - ","description":"","tags":["其他"],"title":"命令行启动 wireshark 抓包","uri":"/posts/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%90%AF%E5%8A%A8wireshark%E6%8A%93%E5%8C%85/"},{"categories":["golang"],"content":"普通代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package main import \"fmt\" type Code int const ( OK Code = 1 BadRequest Code = 2 InvalidParam Code = 3 ) func main() { fmt.Println(BadRequest) } 运行结果：\n1 2 3 4 $ ls go.mod go.sum main.go $ go run . 2 Code是int类型，正常情况下，输出是整形数字。\n使用 go generate 和 stringer 下面看下使用go generate和官方的stringer是什么效果。\n安装 1 go install golang.org/x/tools/cmd/stringer 添加标记 在代码的任意地方添加一行 //go:generate stringer -type=Code\n注意，//后面不能有空格\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import \"fmt\" //go:generate stringer -type=Code type Code int const ( OK Code = 1 BadRequest Code = 2 InvalidParam Code = 3 ) func main() { fmt.Println(BadRequest) } 运行结果：\n1 2 3 4 5 $ go generate $ ls code_string.go go.mod go.sum main.go $ go run . BadRequest 执行go generate后，会生成一个 code_string.go 的文件，其内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Code generated by \"stringer -type=Code\"; DO NOT EDIT. package main import \"strconv\" func _() { // An \"invalid array index\" compiler error signifies that the constant values have changed. // Re-run the stringer command to generate them again. var x [1]struct{} _ = x[OK-1] _ = x[BadRequest-2] _ = x[InvalidParam-3] } const _Code_name = \"OKBadRequestInvalidParam\" var _Code_index = [...]uint8{0, 2, 12, 24} func (i Code) String() string { i -= 1 if i \u003c 0 || i \u003e= Code(len(_Code_index)-1) { return \"Code(\" + strconv.FormatInt(int64(i+1), 10) + \")\" } return _Code_name[_Code_index[i]:_Code_index[i+1]] } 当代码中再次打印 Code 值的时候，输出不再是整形数字，而是变成了字符串，并且是对应的变量名称。\n更多用法 如果再增加一个-linecomment参数，变成//go:generate stringer -type=Code -linecomment，表示打印的时候从注释取值，具体效果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import \"fmt\" //go:generate stringer -type=Code -linecomment type Code int const ( OK Code = 1 // 正常OK BadRequest Code = 2 // 请求错误 InvalidParam Code = 3 ) func main() { fmt.Println(BadRequest) fmt.Println(InvalidParam) } 执行go generate后生成的 code_string.go 内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Code generated by \"stringer -type=Code -linecomment\"; DO NOT EDIT. package main import \"strconv\" func _() { // An \"invalid array index\" compiler error signifies that the constant values have changed. // Re-run the stringer command to generate them again. var x [1]struct{} _ = x[OK-1] _ = x[BadRequest-2] _ = x[InvalidParam-3] } const _Code_name = \"正常OK请求错误InvalidParam\" var _Code_index = [...]uint8{0, 8, 20, 32} func (i Code) String() string { i -= 1 if i \u003c 0 || i \u003e= Code(len(_Code_index)-1) { return \"Code(\" + strconv.FormatInt(int64(i+1), 10) + \")\" } return _Code_name[_Code_index[i]:_Code_index[i+1]] } 运行结果：\n1 2 3 $ go run . 请求错误 InvalidParam 可见，加了-linecomment参数后，如果变量有注释，则打印内容默认为注释，否则默认为变量名称。\n更多参数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ stringer -h Usage of stringer: stringer [flags] -type T [directory] stringer [flags] -type T files... # Must be a single package For more information, see: https://pkg.go.dev/golang.org/x/tools/cmd/stringer Flags: -linecomment use line comment text as printed text when present -output string output file name; default srcdir/\u003ctype\u003e_string.go -tags string comma-separated list of build tags to apply -trimprefix prefix trim the prefix from the generated constant names -type string comma-separated list of type names; must be set ","description":"","tags":["golang","代码生成"],"title":"Golang 的 generate stringer","uri":"/posts/go-generate-stringr/"},{"categories":["docker"],"content":"配置自定义仓库地址 Linux 下创建并修改 /etc/docker/daemon.json\n1 2 3 4 5 6 7 8 { \"registry-mirrors\": [ \"https://a.b.c\", ], \"insecure-registries\": [ \"192.168.199.100:5000\" ] } ","description":"","tags":["docker"],"title":"docker 仓库","uri":"/posts/docker%E4%BB%93%E5%BA%93/"},{"categories":["golang"],"content":"方法 https://www.pengrl.com/p/41755/\n1 2 3 4 5 6 7 8 # 编译出带检测的程序 $go build -race # 跑test时带检测功能 $go test -race # 直接允许也可以添加 $go run -race main.go 该方法是运行时检测，而非静态代码检测。跑 test 和跑程序时都可以添加该参数来检测。\n运行时额外消耗 一般来说，内存会增加 5 到 10 倍，执行时间增加 2 到 20 倍。\n个人建议在开发环境对性能要求不高时可默认打开 race，在项目达到一定阶段，也可以打开 race 跑一些压测做检查。\n","description":"","tags":["golang"],"title":"Go 竞态检测","uri":"/posts/go-race/"},{"categories":["golang"],"content":"go build -ldflags 有如下示例代码：\n1 2 3 4 5 6 7 8 9 10 11 package main import ( \"fmt\" ) var Version = \"undefined\" func main() { fmt.Println(\"Version:\", Version) } 第一种用法：\n1 2 3 4 5 $ go run main.go Version: undefined $ go run -ldflags '-X main.Version=1.0' main.go Version: 1.0 第二种用法：\n1 \"-X main.Version=`{shell cmd}`\" 1 2 3 4 5 $ git rev-parse HEAD 90cb4c8a3376b967960a2185b3acc669734f5e33 $ go run -ldflags \"-X main.Version=`git rev-parse HEAD`\" main.go Version: 90cb4c8a3376b967960a2185b3acc669734f5e33 go build -trimpath 参数-trimpath可以去除 GOPATH，在打印日志和 panic 信息时有用。\n有如下示例代码\n1 2 3 4 5 package main func main() { panic(\"err\") } 直接go build：\n1 2 3 4 5 6 $ go build \u0026\u0026 ./demo panic: err goroutine 1 [running]: main.main() /Users/admin/demo/main.go:4 +0x25 加参数-trimpath后：\n1 2 3 4 5 6 $ go build -trimpath \u0026\u0026 ./demo panic: err goroutine 1 [running]: main.main() demo/main.go:4 +0x25 CGO_ENABLED=0 go build 默认情况下，通过go env看到CGO_ENABLED=1的设置，表示不将程序依赖的 libc 一起编译到可执行文件，一般情况下没有问题，但是在使用 docker 的时候经常会遇到程序运行不起来，并且一般报的错误是not found, 编译时设置CGO_ENABLED=0环境变量即可解决。\n例如：\n1 CGO_ENABLED=0 go build main.go go vet ./... 用来检测一些基础或常见错误，比如 fmt.Printf(\"%d\", \"hello\")，字符串当数字 print\ngo build -race 用来进行静态竞争检测\n","description":"","tags":["golang"],"title":"Go 编译 tips","uri":"/posts/go-cc-tips/"},{"categories":["其他"],"content":"\n","description":"","tags":["其他"],"title":"开源协议区别","uri":"/posts/%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE%E5%8C%BA%E5%88%AB/"},{"categories":["golang"],"content":"https://segmentfault.com/a/1190000022030353\nhttps://www.51cto.com/article/678037.html\n","description":"","tags":["golang"],"title":"Go 的 gc","uri":"/posts/go-gc/"},{"categories":["redis"],"content":"如果请求 A 抢到了锁，但是业务处理时间过长，导致分布式锁被 Redis 释放，此时请求 B 过来的时候，会造成并发问题，导致业务出错，怎么解决。\n只需要在请求 A 获得锁的同时，创建一个监控程序，当任务未处理完，而锁快过期的时候，延长锁的过期时间即可。\nhttps://www.51cto.com/article/742568.html\n","description":"","tags":["redis"],"title":"分布式锁提前过期","uri":"/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%8F%90%E5%89%8D%E8%BF%87%E6%9C%9F/"},{"categories":["算法"],"content":"参考：\nhttps://halfrost.com/lru_lfu_interview/\nhttps://developer.aliyun.com/article/928903\n使用 map + 双向链表的方式实现 LRU：\n双向链表存储数据\nmap 存储链表的指针\n更新时，map 判断在不在链表里，在的话将该节点放到头部，使用双向指针找到前后的节点并连接起来。\n","description":"","tags":["算法"],"title":"LRU","uri":"/posts/lru/"},{"categories":["golang"],"content":"参考：https://learnku.com/articles/41728\nG：协程 P：调度器 M：操作系统线程\n个数关系： ","description":"","tags":["golang"],"title":"Go 的 GPM 模型","uri":"/posts/go-gpm/"},{"categories":["golang"],"content":"概念 所谓内存逃逸，指的是原来应该分配在栈上的变量，被分配到了堆上。\n为什么需要关注内存逃逸 栈上的内存不需要 GC，堆上的内存需要 GC。 堆上分配的内存的效率低于栈。 安全问题。。。？ 所以内存逃逸分析有助于减少 GC 压力。\n举例 函数中申请大切片，所需内存超过了栈的限制，会被分配到堆上 1 var slice = make([]string, 999999999999) 函数返回了对象的指针 1 2 3 4 5 6 7 8 type User struct { name string } func T() *User { user := new(User) return user } 函数中创建的变量，赋值给了全局变量 1 2 3 4 5 6 var s []int func T(){ s = make([]int, 10) return } ","description":"","tags":["golang"],"title":"Go 内存逃逸","uri":"/posts/go%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"},{"categories":["消息队列"],"content":"参考：https://rocketmq.apache.org/zh/docs/featureBehavior/04transactionmessage/\n简单讲，业务上的事务包含（数据库事务 + 消息事务），原先生产者只能控制数据库事务的提交或回滚，RocketMQ 使用消息确认的机制将这两者进行了关联，大致代码执行逻辑为：\n生产者设置消息回查接口（供 mq 查询事务是否完成） 生产者先发送半消息 执行数据库事务 本地事务提交 提交消息事务 处理 mq 回查消息，返回本地事务结果 ","description":"","tags":["消息队列"],"title":"rocketmq 事务消息","uri":"/posts/rocketmq%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"},{"categories":["消息队列"],"content":"参考：\nhttps://www.tizi365.com/question/4832.html\nhttps://www.cnblogs.com/FlyAway2013/p/10124283.html\n简单的讲，就是生产方需要多维护一个已发送消息的数据表（与业务表在一个库，方便执行业务事务），发送完 MQ 消息后等待消费方回调后再更新本地消息表。\n如果消费方没有回调，则本地定时任务进行重新投递确认，确保最终一致性。\n如果使用支持事务消息的 RocketMQ，可以简化这个步骤，不需要维护本地消息表。\n","description":"","tags":["消息队列"],"title":"本地消息表","uri":"/posts/%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8/"},{"categories":["算法"],"content":"\n","description":"","tags":["算法"],"title":"map-reduce","uri":"/posts/map-reduce/"},{"categories":["linux"],"content":" 1 2 3 4 5 # 仅仅是不启用 $ systemctl disable YOUR_SERVICE # 屏蔽服务，无法使用systemctl start YOUR_SERVICE $ systemctl mask YOUR_SERVICE ","description":"","tags":["linux"],"title":"systemctl","uri":"/posts/systemctl/"},{"categories":["mysql"],"content":"间隙锁产生的条件 使用 \u003e 、 \u003c 、between 等区间条件 delete 不存在的数据 间隙锁的例子 当我们通过一个参数去删除一条记录的时候，如果参数在数据库中存在，那么这个时候产生的是普通行锁，锁住这个记录，然后删除，然后释放锁。如果这条记录不存在，问题就来了，数据库会扫描索引，发现这个记录不存在，这个时候的 delete 语句获取到的就是一个间隙锁，然后数据库会向左扫描扫到第一个比给定参数小的值，向右扫描扫描到第一个比给定参数大的值，然后以此为界，构建一个区间，锁住整个区间内的数据。\n总结 两个事务即使生成的间隙锁 (next-key 锁) 的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。\n在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后插入意向锁和间隙锁之间是互斥的关系。\n如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：互斥、占有且等待、不可强占用、循环等待，因此发生了死锁。\n参考连接 https://cloud.tencent.com/developer/article/1806998\nhttps://www.xiaolincoding.com/mysql/lock/show_lock.html\n","description":"","tags":["mysql"],"title":"间隙锁和死锁","uri":"/posts/%E9%97%B4%E9%9A%99%E9%94%81%E5%92%8C%E6%AD%BB%E9%94%81/"},{"categories":["mysql"],"content":"在 SQL 中，我们可以用 COUNT 函数来计算某个表中某个列的行数。但是，有些人可能不知道 COUNT() 函数有三种不同的用法：count(*)，count(1)，和 count(列)。这三种用法的区别如下：\ncount(*) count(*) 会统计表中所有行的数量，包括 NULL 值。例如，如果有一个表有 10 行，其中有 2 行的列值是 NULL，那么 count(*) 将返回 10。\ncount(1) count(1) 也会统计表中所有行的数量，包括 NULL 值。但是，它不会实际检索任何数据，而是使用数字 1 来代替每一行的值。例如，如果有一个表有 10 行，其中有 2 行的列值是 NULL，那么 count(1) 将返回 10。\ncount(列) count(列) 只会统计列中非 NULL 值的数量。例如，如果有一个表有 10 行，其中有 2 行的列值是 NULL，而其他 8 行的列值是非 NULL 值，那么 count(列) 将返回 8。\n综上所述，count(*) 和 count(1) 会统计表中所有行的数量，包括 NULL 值，而 count(列) 只会统计列中非 NULL 值的数量。在使用 COUNT() 函数时，需要根据实际需求选择不同的用法。\n建表语句：\n1 2 3 4 5 CREATE TABLE `users` ( `id` int NOT NULL AUTO_INCREMENT, `username` varchar(50) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB ","description":"","tags":["mysql"],"title":"MySQL count(*)、count(1)、count(列) 的区别","uri":"/posts/mysql-count/"},{"categories":["mysql"],"content":"查看用户 1 SELECT* FROM mysql.user;` 创建用户 1 2 3 CREATE USER 'testuser'@'localhost' IDENTIFIED BY 'password'; CREATE USER 'testuser'@'192.168.10.100' IDENTIFIED BY 'password'; CREATE USER 'testuser'@'%' IDENTIFIED BY 'password'; 授权 1 2 3 GRANT ALL PRIVILEGES ON testdb.* TO 'testuser'@'localhost'; GRANT ALL PRIVILEGES ON *.* TO 'testuser'@'localhost'; GRANT SELECT, INSERT, DELETE ON testdb1.* TO testuser@'localhost'; 持久化权限配置 一般不需要执行\ngrant 之后要跟着 flush privileges 吗？-极客时间\n1 flush privileges; 查看权限 1 SHOW GRANTS FOR 'testuser'@'localhost'; ","description":"","tags":["mysql"],"title":"MySQL8 创建用户和授权","uri":"/posts/mysql-create-user-auth/"},{"categories":["mysql"],"content":" 1 2 3 4 5 6 7 $ mysql -u root -p \u003e use mysql; \u003e GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION; \u003e FLUSH PRIVILEGES; ","description":"","tags":["mysql"],"title":"MySQL 允许 root 远程访问","uri":"/posts/mysql-remote-root/"},{"categories":["mysql"],"content":"参考 讲的比较清晰的：https://www.51cto.com/article/679914.html\n理论 MySQL 中事务的隔离级别一共分为四种，分别如下：\n序列化 (SERIALIZABLE) 可重复读 (REPEATABLE READ) 提交读 (READ COMMITTED) 未提交读 (READ UNCOMMITTED) 四种不同的隔离级别含义分别如下：\n1）.SERIALIZABLE\n如果隔离级别为序列化，则用户之间通过一个接一个顺序地执行当前的事务，这种隔离级别提供了事务之间最大限度的隔离。\n2）.REPEATABLE READ（默认级别）\n在可重复读在这一隔离级别上，事务不会被看成是一个序列。不过，当前正在执行事务的变化仍然不能被外部看到，也就是说，如果用户在另外一个事务中执行同条 SELECT 语句数次，结果总是相同的。(因为正在执行的事务所产生的数据变化不能被外部看到)。\n3）.READ COMMITTED\nREAD COMMITTED 隔离级别的安全性比 REPEATABLE READ 隔离级别的安全性要差。处于 READ COMMITTED 级别的事务可以看到其他事务对数据的修改。也就是说，在事务处理期间，如果其他事务修改了相应的表，那么同一个事务的多个 SELECT 语句可能返回不同的结果。\n4）.READ UNCOMMITTED\nREAD UNCOMMITTED 提供了事务之间最小限度的隔离。除了容易产生虚幻的读操作和不能重复的读操作外，处于这个隔离级的事务可以读到其他事务还没有提交的数据，如果这个事务使用其他事务不提交的变化作为计算的基础，然后那些未提交的变化被它们的父事务撤销，这就导致了大量的数据变化。\n在 MySQL 数据库中，默认的事务隔离级别是 REPEATABLE READ Q\u0026A Q: 在读未提交隔离级别下，快照是什么时候生成的？\nA: 没有快照，因为不需要，怎么读都读到最新的。不管是否提交\nQ: 在读已提交隔离级别下，快照是什么时候生成的？\nA: SQL 语句开始执行的时候。\nQ: 在可重复读隔离级别下，快照是什么时候生成的？\nA: 事务开始的时候。\n","description":"","tags":["mysql"],"title":"MySQL 事务","uri":"/posts/mysql-transaction/"},{"categories":["mysql"],"content":"SQL 执行过程 为什么使用 B+ 数 一句话，主要是为了更好的性能。B+ 数只有叶子节点存储数据，其他节点存储的是索引；\n因为 MySQL 是以页为基本单位读取数据的，同时 B+ 树中的节点大小也是页，B+ 树非叶子节点用来存放索引而不是实际的业务数据，所以每页（每个节点）可以存储更多条记录，所以树的高度更低，所以查询数据需要的磁盘 IO 更少。\n什么是索引 索引是 MySQL 为了加快查询速度生成的数据结构，利用空间换时间，每一个索引都对应一颗 B+ 树。\n索引的缺点是占用磁盘空间、降低数据更新性能。\n参考：https://zhuanlan.zhihu.com/p/481750465 索引有几种类型 聚簇索引（一级索引） 主键索引 非聚簇索引（二级索引） 普通索引 唯一索引 联合索引 全文索引 什么是前缀索引 前缀索引能有效减小索引文件的大小，让每个索引页可以保存更多的索引值，从而提高了索引查询的速度。但前缀索引也有它的缺点，不能在 order by 或者 group by 中触发前缀索引，也不能把它们用于覆盖索引。\n参考：https://blog.51cto.com/u_15311952/3186968\n创建索引的原则 给 where 后面经常用到的字段加索引\n数据量很小的表可以不创建索引，可能会变慢\n列值重复度高的不要创建索引，没效果\n索引的数量不要太多，建议 3-5 个\n索引尽量的短，可以使 B+ 树节点存储更多的索引量\n可以长度很长的列值创建前缀索引\n参考：https://www.jianshu.com/p/fc80445044cc\n什么情况下索引失效 违反最左前缀匹配原则，如组合索引 idx_name_phone，where phone=12345 不用索引，where name=”abc”使用了索引，where name=”abc”and phone=12345 也使用索引。 使用反向查询（≠ 、\u003c\u003e、not like） 使用 like“%abc”这种查询条件，但是 like“abc%”不影响。 使用OR连接的查询语句，如果OR之前的条件列是索引列，但是OR之后的条件列不是索引列，则不会使用索引。 对索引列使用函数、计算、类型转换等操作 什么是回表 如果索引的列在 select 所需获得的列中（因为在 mysql 中索引是根据索引列的值进行排序的，所以索引节点中存在该列中的部分值）或者根据一次索引查询就能获得记录就不需要回表，如果 select 所需获得列中有大量的非索引列，索引就需要到表中找到相应的列的信息，这就叫回表。\n什么是索引覆盖 查询的字段包含在索引里面，不需要回表，称为索引覆盖。\n只需要在一棵索引树上就能获取 SQL 所需的所有列数据，无需回表，速度更快。\nexplain 的输出结果 Extra 字段为 Using index 时，能够触发索引覆盖。\nMySQL 的锁机制 锁和索引关系密切。update 默认开启事务，根据 where 条件决定\n有索引的情况下：\n行锁：锁住要更新的 1 行或多行，比如 id \u003e xx\n记录锁：对存在的行加锁。 间隙锁：对不存在的行加锁。 临建锁：可能会锁住一些不存在的行，比如数据库里只有 ID=101，ID=105，ID=106 的行，但是执行的是 where id \u003e 100，此时对 ID=200，ID=102 等的行插入也是不行的。 没索引的情况下：\n修改表结构会使用表锁，所有增删改查都需要等待。\n表锁：如果没用到索引，则行锁会升级为表锁\n为什么建议数据库要有主键 为了方便数据存储和查询，如果没有主键，MySQL 默认会使用一个 rowid 代替，但是这个 rowid 达到上限后会从 0 开始，再插入数据会导致原来的数据记录被覆盖，所以不安全。\n如果指定了一个主键 ID，同样达到上限后，再次插入会报错但不会覆盖数据，业务上更安全。\n一般 int 上限是 2^32=42 亿，如果换成 big int，会是 2^64=无穷大。\n如果考虑到以后会分库分表，不建议使用自增主键，建议使用雪花算法生成主键 ID。\n为什么删除了数据磁盘文件大小不变 首先，MySQL 数据是按页存储的，因为 MySQL 删除数据只是给数据一个已删除的标记，并不会真正删除数据。\nMySQL 数据碎片 数据碎片主要是因为 MySQL 删除数据后导致的数据空洞，可以通过重新建表的方式消除。\n如果数据库里本身没有空洞，执行重新建表后，可能会使存储空间变大，原因是每页中除了数据外，还要存储其他的信息。\n脏读 \u0026 幻读 脏读又称无效数据的读出，是指在数据库访问中，事务 T1 将某一值修改，然后事务 T2 读取该值，此后 T1 因为某种原因撤销对该值的修改，这就导致了 T2 所读取到的数据是无效的，值得注意的是，脏读一般是针对于 update 操作的。\n不可重复读 是指 A 事务开始时读取一个结果 N，中间因为另一个事务 B 又提交了数据，导致 A 事务再次读取时拿到结果 N‘ ，造成前后数据不一致，这种称为不可重复读。\n","description":"","tags":["mysql"],"title":"MySQL 常识","uri":"/posts/mysql-common/"},{"categories":["golang"],"content":"参考：https://www.cnblogs.com/qcrao-2018/p/12833787.html\n","description":"","tags":["golang"],"title":"Go sync map 实现","uri":"/posts/go-sync-map/"},{"categories":["redis"],"content":"哨兵 参考：https://www.cnblogs.com/kevingrace/p/9004460.html\nsentinel 系统可以监视一个或者多个 redis master 服务，以及这些 master 服务的所有从服务；当某个 master 服务下线时，自动将该 master 下的某个从服务升级为 master 服务替代已下线的 master 服务继续处理请求。 集群模式下的请求 参考： https://zhuanlan.zhihu.com/p/511199672\n集群模式是去中心化的，随便请求到哪个 master 后，判断 key 属于哪个 hash 槽以及在哪个机器上，进行请求路由。\nredis 热点 key 单机 QPS 瓶颈后，可以用集群分片，来分担请求压力，但是如果一个 key 就是在某一个分片上形成了热点 key 怎么办。\n对 key 的值在业务上拆分，使其分散到更多的分片上。\n或者如果 key 对应的数据允许有一定的误差，可以将该值存在进程内存里，做二级缓存，定时同步 redis 即可。\n查看大 key redis-cli -h 127.0.0.1 -p 6379 --bigkeys\n使用 scan 扫描，对性能影响较小\n查看状态 redis-cli -h 127.0.0.1 -p 6379 --stat -i 3\n-i 3 每隔 3 秒输出一次\nre-hash 过程 数据结构里存放了两个 hash 结构，一个是当前的，一个是 rehash 时候使用的。\n数据从旧结构往新结构迁移，为了不影响查询和插入，是渐进式的，新数据写新结构。\n问题 Q：怎么保证高性能、高可用和数据不丢失\n使用集群分片保证请求的离散来突破单机 QOS 瓶颈。\n使用主从模式保证数据的不丢失。\n使用哨兵模式监控 master 可用性，及时提升从服务为主服务，来保证高可用。\n","description":"","tags":["redis"],"title":"redis 备忘录","uri":"/posts/redis%E5%A4%87%E5%BF%98%E5%BD%95/"}]
